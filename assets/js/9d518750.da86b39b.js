"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[864],{9973:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>a,contentTitle:()=>i,default:()=>d,frontMatter:()=>s,metadata:()=>c,toc:()=>h});var o=t(5893),r=t(1151);const s={sidebar_label:"LibTorch"},i="LibTorch (PyTorch C++ Frontend)",c={id:"AI-engineering/LibTorch",title:"LibTorch (PyTorch C++ Frontend)",description:"LibTorch is the official C++ frontend for Pytorch. However, due to its lack of documentation, I encountered lots of confusions during its use. Some useful tips/tricks are listed here just FYI.",source:"@site/kb/AI-engineering/LibTorch.md",sourceDirName:"AI-engineering",slug:"/AI-engineering/LibTorch",permalink:"/kb/AI-engineering/LibTorch",draft:!1,unlisted:!1,editUrl:"https://github.com/yechs/website/edit/master/kb/AI-engineering/LibTorch.md",tags:[],version:"current",lastUpdatedAt:1625583093e3,frontMatter:{sidebar_label:"LibTorch"},sidebar:"kbSidebar",previous:{title:"Yarn Version Manager",permalink:"/kb/webdev/yarn"},next:{title:"Export Model w/ Weights",permalink:"/kb/AI-engineering/Model-export"}},a={},h=[{value:"Performance: slower than Python",id:"performance-slower-than-python",level:2},{value:"Cross-Save/Load Tensors in Python",id:"cross-saveload-tensors-in-python",level:2},{value:"Save tensor in C++ and load in Python",id:"save-tensor-in-c-and-load-in-python",level:3},{value:"Save tensor in Python and load in C++",id:"save-tensor-in-python-and-load-in-c",level:3},{value:"Alternative: use pickle",id:"alternative-use-pickle",level:3},{value:"Multiple Input/Output for Inference",id:"multiple-inputoutput-for-inference",level:2}];function l(e){const n={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",p:"p",pre:"pre",...(0,r.a)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.header,{children:(0,o.jsx)(n.h1,{id:"libtorch-pytorch-c-frontend",children:"LibTorch (PyTorch C++ Frontend)"})}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.a,{href:"https://pytorch.org/cppdocs/frontend.html",children:"LibTorch"})," is the official C++ frontend for Pytorch. However, due to its lack of documentation, I encountered lots of confusions during its use. Some useful tips/tricks are listed here just FYI."]}),"\n",(0,o.jsx)(n.p,{children:"As of July 2021, this documentation is written based on my experience with libtorch v1.9"}),"\n",(0,o.jsx)(n.h2,{id:"performance-slower-than-python",children:"Performance: slower than Python"}),"\n",(0,o.jsxs)(n.p,{children:["It is repeatedly reported that inference using LibTorch is much slower than that in Python. See discussions in ",(0,o.jsx)(n.a,{href:"https://github.com/pytorch/pytorch/issues/19106",children:"#19106"}),"."]}),"\n",(0,o.jsxs)(n.p,{children:["There is also ",(0,o.jsx)(n.a,{href:"https://zhuanlan.zhihu.com/p/363319763",children:"a ZhiHu article"})," (in Chinese) that attempts to analyze this issue in-depth. The solution it proposed was to recompile libtorch by linking to libraries used by pytorch."]}),"\n",(0,o.jsx)(n.h2,{id:"cross-saveload-tensors-in-python",children:"Cross-Save/Load Tensors in Python"}),"\n",(0,o.jsx)(n.p,{children:"This section documents how to save tensors in C++ and load them into Python, and vice versa. It is often done for more friendly debugging experience offered by the Python frontend."}),"\n",(0,o.jsx)(n.admonition,{type:"info",children:(0,o.jsxs)(n.p,{children:["Note that LibTorch ",(0,o.jsx)(n.code,{children:"torch::save()"})," function (",(0,o.jsx)(n.a,{href:"https://github.com/pytorch/pytorch/blob/v1.9.0/torch/csrc/api/include/torch/serialize.h#L11-L45",children:"source"}),") saves the tensors in a wrapped TorchScript (JIT) module, unlike ",(0,o.jsx)(n.code,{children:"torch.save()"})," (",(0,o.jsx)(n.a,{href:"https://pytorch.org/docs/1.9.0/generated/torch.save.html",children:"docs"}),") in Python."]})}),"\n",(0,o.jsx)(n.h3,{id:"save-tensor-in-c-and-load-in-python",children:"Save tensor in C++ and load in Python"}),"\n",(0,o.jsxs)(n.p,{children:["In C++, call ",(0,o.jsx)(n.code,{children:"torch::save()"})," to save."]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-cpp",children:'#include <torch/torch.h>\n\n// save one tensor\ntorch::save(tensor, "tensor.pt");\n\n// save multiple tensors\ntorch::save({tensora, tensorb, tensorc}, "tensors.pt");\n'})}),"\n",(0,o.jsxs)(n.p,{children:["In Python, use ",(0,o.jsx)(n.code,{children:"torch.jit.load()"})," to load."]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'import torch\n\n# Load one tensor\ntensor_model = torch.jit.load("tensor.pt")\ntensor = list(tensor_model.parameters())[0]\n\n# Load multiple tensors\ntensors_model = torch.jit.load("tensors.pt")\ntensora = list(tensors_model.parameters())[0]\ntensorb = list(tensors_model.parameters())[1]\ntensorc = list(tensors_model.parameters())[2]\n'})}),"\n",(0,o.jsx)(n.h3,{id:"save-tensor-in-python-and-load-in-c",children:"Save tensor in Python and load in C++"}),"\n",(0,o.jsxs)(n.p,{children:["The following codes are adapted from ",(0,o.jsx)(n.a,{href:"https://github.com/pytorch/pytorch/issues/20356#issuecomment-545572400",children:"pytorch/pytorch#20356 (comment)"})," and updated for the v1.8+ API (",(0,o.jsx)(n.code,{children:"get_attribute"})," => ",(0,o.jsx)(n.code,{children:"attr"}),")."]}),"\n",(0,o.jsx)(n.p,{children:"Save tensors in Python: to do so, you have to create a model and include all tensors into this TorchScript module."}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:"import torch\n\nclass Container(torch.nn.Module):\n    def __init__(self, my_values):\n        super().__init__()\n        for key in my_values:\n            setattr(self, key, my_values[key])\n\nmy_values = {\n    'a': torch.ones(2, 2),\n    'b': torch.ones(2, 2) + 10,\n    'c': 'hello',\n    'd': 6\n}\n\n# Save arbitrary values supported by TorchScript\n# https://pytorch.org/docs/master/jit.html#supported-type\ncontainer = torch.jit.script(Container(my_values))\ncontainer.save(\"container.pt\")\n"})}),"\n",(0,o.jsx)(n.p,{children:"Load tensors in C++"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-cpp",children:'#include <torch/script.h>\n\ntorch::jit::script::Module container = torch::jit::load("container.pt");\n\ntorch::Tensor a = container.attr("a").toTensor();\ntorch::Tensor b = container.attr("b").toTensor();\nstd::string c = container.attr("c").toStringRef();\n\nint64_t d = container.attr("d").toInt();\n'})}),"\n",(0,o.jsx)(n.h3,{id:"alternative-use-pickle",children:"Alternative: use pickle"}),"\n",(0,o.jsxs)(n.p,{children:["An alternative is to use ",(0,o.jsx)(n.code,{children:"pickle_save"})," and ",(0,o.jsx)(n.code,{children:"pickle_load"})," (",(0,o.jsx)(n.a,{href:"https://github.com/pytorch/pytorch/blob/v1.9.0/torch/csrc/api/include/torch/serialize.h#L76-L77",children:"source"}),"). See ",(0,o.jsx)(n.a,{href:"https://github.com/pytorch/pytorch/issues/20356#issuecomment-782341150",children:"this comment in pytorch/pytorch#20356"})," for usage."]}),"\n",(0,o.jsx)(n.h2,{id:"multiple-inputoutput-for-inference",children:"Multiple Input/Output for Inference"}),"\n",(0,o.jsxs)(n.p,{children:["Suppose we have loaded a model named ",(0,o.jsx)(n.code,{children:"module"})," and want to use it for inference. However, the model requires multiple inputs/outputs."]}),"\n",(0,o.jsxs)(n.p,{children:["The codes are adapted from ",(0,o.jsx)(n.a,{href:"https://github.com/pytorch/pytorch/issues/18337",children:"pytorch/pytorch#18337"}),"."]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-cpp",children:"std::vector<torch::jit::IValue> inputs;\ninputs.push_back(tensora);\ninputs.push_back(tensorb);\n\nauto outputs = module->forward(inputs).toTuple();\n\ntorch::Tensor out1 = outputs->elements()[0].toTensor();\ntorch::Tensor out2 = outputs->elements()[1].toTensor();\n"})}),"\n",(0,o.jsx)(n.admonition,{type:"info",children:(0,o.jsxs)(n.p,{children:["Note: if you only have one output, you can directly call ",(0,o.jsx)(n.code,{children:"toTensor()"})," on the output of ",(0,o.jsx)(n.code,{children:"forward()"}),"."]})})]})}function d(e={}){const{wrapper:n}={...(0,r.a)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(l,{...e})}):l(e)}},1151:(e,n,t)=>{t.d(n,{Z:()=>c,a:()=>i});var o=t(7294);const r={},s=o.createContext(r);function i(e){const n=o.useContext(s);return o.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function c(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:i(e.components),o.createElement(s.Provider,{value:n},e.children)}}}]);